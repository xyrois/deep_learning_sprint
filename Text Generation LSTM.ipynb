{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "XcmrucxjGz1z",
        "outputId": "a9dd6021-b2ed-4aa7-ffe6-456b044702ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394\n",
            "Training sequences: (1115294, 100)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m17427/17427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1041s\u001b[0m 60ms/step - loss: 1.8376\n",
            "Epoch 2/3\n",
            "\u001b[1m17427/17427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1036s\u001b[0m 59ms/step - loss: 1.3293\n",
            "Epoch 3/3\n",
            "\u001b[1m17427/17427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1036s\u001b[0m 59ms/step - loss: 1.2696\n",
            "===== Generated Text (Temp = 0.5) =====\n",
            "Shall I compare thee:\n",
            "I am ancient time and state and follow'd.\n",
            "\n",
            "PETRUCHIO:\n",
            "All this is the day of men are sorrow.\n",
            "\n",
            "CLARENCE:\n",
            "I do not be a strength to my son of me.\n",
            "\n",
            "CLARENCE:\n",
            "Farewell, come hither, come.\n",
            "\n",
            "AUTOLYCUS:\n",
            "I \n",
            "\n",
            "===== Generated Text (Temp = 1.0) =====\n",
            "Shall I compare thee:\n",
            "And tell you, siely and his worn of fear\n",
            "A bell, he doth raised aallianton\n",
            "Than in the child. No, I'll come on him:\n",
            "And in these child, made a little shall\n",
            "hear it, and in my bristal men I must now,\n",
            "\n",
            "===== Generated Text (Temp = 1.5) =====\n",
            "Shall I compare thee, in why,--\n",
            "Hare, nories homing? why cut him learncelly\n",
            "Think thee to his kitw? a' callar\n",
            "Off; but, leoss--youchen; ore 'tis elsener,--\n",
            "SciliCuld, be leong witch her adved Richmond?.\n",
            "Hark looks helven\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 1. LOAD & PREPARE TEXT DATA (using Shakespeare)\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# Download Shakespeare dataset\n",
        "path_to_file = tf.keras.utils.get_file(\n",
        "    \"shakespeare.txt\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n",
        ")\n",
        "\n",
        "# Load text\n",
        "text = open(path_to_file, \"r\", encoding=\"utf-8\").read()\n",
        "print(\"Length of text:\", len(text))\n",
        "\n",
        "# Get unique characters\n",
        "unique_chars = sorted(list(set(text)))\n",
        "vocab_size = len(unique_chars)\n",
        "\n",
        "char_to_idx = {c: i for i, c in enumerate(unique_chars)}\n",
        "idx_to_char = {i: c for i, c in enumerate(unique_chars)}\n",
        "\n",
        "# Encode text → integers\n",
        "encoded_text = np.array([char_to_idx[c] for c in text])\n",
        "\n",
        "sequence_length = 100  # Shakespeare benefits from longer context\n",
        "sequences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(encoded_text) - sequence_length):\n",
        "    seq = encoded_text[i:i + sequence_length]\n",
        "    next_c = encoded_text[i + sequence_length]\n",
        "    sequences.append(seq)\n",
        "    next_chars.append(next_c)\n",
        "\n",
        "X = np.array(sequences)\n",
        "y = tf.keras.utils.to_categorical(next_chars, num_classes=vocab_size)\n",
        "\n",
        "print(\"Training sequences:\", X.shape)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 2. BUILD LSTM MODEL (follows starter code)\n",
        "# ----------------------------------------------------\n",
        "embedding_dim = 256\n",
        "lstm_units = 512\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=sequence_length),\n",
        "    LSTM(lstm_units, return_sequences=True),\n",
        "    LSTM(lstm_units),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 3. TRAIN MODEL\n",
        "# ----------------------------------------------------\n",
        "EPOCHS = 3\n",
        "model.fit(X, y, batch_size=64, epochs=EPOCHS)\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 4. TEXT GENERATION FUNCTION\n",
        "# ----------------------------------------------------\n",
        "def generate_text(seed_text, length=200, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generates text using trained LSTM.\n",
        "    \"\"\"\n",
        "    generated = seed_text\n",
        "\n",
        "    for _ in range(length):\n",
        "        # Convert seed to integers\n",
        "        seed_encoded = np.array([char_to_idx[c] for c in seed_text[-sequence_length:]])\n",
        "\n",
        "        # Pad if too short\n",
        "        seed_encoded = np.pad(\n",
        "            seed_encoded,\n",
        "            (sequence_length - len(seed_encoded), 0),\n",
        "            mode=\"constant\"\n",
        "        )\n",
        "\n",
        "        seed_encoded = np.expand_dims(seed_encoded, axis=0)\n",
        "\n",
        "        # Predict next character\n",
        "        preds = model.predict(seed_encoded, verbose=0)[0]\n",
        "\n",
        "        # Temperature sampling\n",
        "        preds = np.asarray(preds).astype(\"float64\")\n",
        "        preds = np.log(preds + 1e-9) / temperature\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        next_idx = np.random.choice(len(preds), p=preds)\n",
        "        next_char = idx_to_char[next_idx]\n",
        "\n",
        "        generated += next_char\n",
        "        seed_text += next_char\n",
        "\n",
        "    return generated\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 5. EXAMPLE GENERATED OUTPUTS\n",
        "# ----------------------------------------------------\n",
        "print(\"===== Generated Text (Temp = 0.5) =====\")\n",
        "print(generate_text(\"Shall I compare thee\", temperature=0.5))\n",
        "\n",
        "print(\"\\n===== Generated Text (Temp = 1.0) =====\")\n",
        "print(generate_text(\"Shall I compare thee\", temperature=1.0))\n",
        "\n",
        "print(\"\\n===== Generated Text (Temp = 1.5) =====\")\n",
        "print(generate_text(\"Shall I compare thee\", temperature=1.5))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}